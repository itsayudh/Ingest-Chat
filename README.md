Ingest and Chat (RAG-based AI Assistant)

This project implements a Retrieval-Augmented Generation (RAG) pipeline using FastAPI, Qdrant, Redis, and Google Gemini API.

It allows you to:

ğŸ“¥ Ingest PDF/Text documents into a vector database (Qdrant).

ğŸ’¬ Chat with your documents using Gemini (LLM).

ğŸ—‚ Maintain chat history with Redis.

ğŸ“… Detect interview booking intents from user queries.

ğŸš€ Features

Document Ingestion
Upload a PDF or text file â†’ itâ€™s chunked, embedded, and stored in Qdrant.

RAG Chat
Ask questions â†’ relevant chunks are retrieved and passed to Gemini for context-aware answers.

Chat History
Conversations are stored in Redis and retrieved per session.

Booking Intent Detection
If a user requests an interview booking, the system extracts:

Name

Email

Date

Time

ğŸ› ï¸ Tech Stack

FastAPI
 â€“ Web framework

Qdrant
 â€“ Vector database for semantic search

Redis
 â€“ Chat history storage

Google Gemini API
 â€“ LLM for generation & intent detection

SentenceTransformers
 â€“ Embedding model
